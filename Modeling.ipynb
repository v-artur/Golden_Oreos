{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/v-artur/Golden_Oreos/blob/main/Modeling.ipynb)"
      ],
      "metadata": {
        "id": "-YwF9Hzt2euf"
      },
      "id": "-YwF9Hzt2euf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import files from drive"
      ],
      "metadata": {
        "id": "gVCNOaaoDSbO"
      },
      "id": "gVCNOaaoDSbO"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2005cbc",
      "metadata": {
        "id": "a2005cbc",
        "outputId": "0fba7964-0587-4e5e-d547-2fe961fdf4e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spectrogram reconstruction "
      ],
      "metadata": {
        "id": "QUch8ZTsGET3"
      },
      "id": "QUch8ZTsGET3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.) One person model"
      ],
      "metadata": {
        "id": "SFlhVaHrGjo-"
      },
      "id": "SFlhVaHrGjo-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for modeling and predicting"
      ],
      "metadata": {
        "id": "HPnNLUrkzd3J"
      },
      "id": "HPnNLUrkzd3J"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "def create_ae_model(inputsize, outputsize):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(inputsize)))\n",
        "    model.add(tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(4, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(outputsize))\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Wk9elaV4zgv3"
      },
      "id": "Wk9elaV4zgv3",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting seed\n",
        "tf.keras.utils.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "xdpHUVGY8wv-"
      },
      "id": "xdpHUVGY8wv-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the optimal structure for one person"
      ],
      "metadata": {
        "id": "wZ5bO6U_yM5h"
      },
      "id": "wZ5bO6U_yM5h"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "data = np.load(r'/content/drive/MyDrive/DeepLearning/features/sub-01_feat.npy')\n",
        "spectrogram = np.load(r'/content/drive/MyDrive/DeepLearning/features/sub-01_spec.npy')\n",
        "\n",
        "#Inital parameters\n",
        "nfolds = 30\n",
        "kf = KFold(nfolds,shuffle=False)\n",
        "pca = PCA()\n",
        "numComps = 500\n",
        "explainedVariance = np.zeros(nfolds)\n",
        "\n",
        "\n",
        "#Initialize an empty spectrogram to save the reconstruction to\n",
        "rec_spec = np.zeros(spectrogram.shape)\n",
        "#Save the correlation coefficients for each fold\n",
        "rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "for k,(train, test) in enumerate(kf.split(data)):\n",
        "          \n",
        "    #Normalization\n",
        "    mu=np.mean(data[train,:],axis=0)\n",
        "    std=np.std(data[train,:],axis=0)\n",
        "    trainData=(data[train,:]-mu)/std\n",
        "    testData=(data[test,:]-mu)/std\n",
        "\n",
        "    #Fit PCA to training data\n",
        "    pca.fit(trainData)\n",
        "    #Get percentage of explained variance by selected components\n",
        "    explainedVariance[k] = np.sum(pca.explained_variance_ratio_[:numComps])\n",
        "    #Tranform data into component space\n",
        "    trainData = np.dot(trainData, pca.components_[:numComps,:].T)\n",
        "    testData = np.dot(testData, pca.components_[:numComps,:].T)\n",
        "\n",
        "    #Autoencoder\n",
        "    early_stopping=EarlyStopping(patience=25, verbose=0, min_delta=1e-5)\n",
        "    checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=0)\n",
        "\n",
        "    model = create_ae_model(numComps, spectrogram.shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    model.fit(trainData, spectrogram[train, :], batch_size=64, \n",
        "              epochs=500, verbose=0, validation_split=1/9, shuffle=True,\n",
        "              callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "    #predict with the Autoencoder\n",
        "    rec_spec[test, :] = model.predict(testData, verbose=0)\n",
        "\n",
        "    #Evaluate reconstruction of this fold\n",
        "    for specBin in range(spectrogram.shape[1]):\n",
        "         #if np.any(np.isnan(rec_spec)):\n",
        "          #          print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "         r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "         rs[k,specBin] = r\n",
        "\n",
        "\n",
        "#Show evaluation result\n",
        "print('mean correlation', np.mean(rs))"
      ],
      "metadata": {
        "id": "ZHp3r8AIyUfI",
        "outputId": "93bbfe31-83bc-49a0-be97-ffe2c7279398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZHp3r8AIyUfI",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean correlation 0.5960884156699534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31c0796a",
      "metadata": {
        "id": "31c0796a",
        "outputId": "fe1e224e-354d-4f60-ed10-dfef7396dffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a44b39bb2b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m             model.fit(trainData, spectrogram[train, :], batch_size=64, \n\u001b[1;32m     93\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                       callbacks=[checkpointer, early_stopping])\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m#predict with the Autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wavfile\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#import reconstructWave as rW\n",
        "#import MelFilterBank as mel\n",
        "\n",
        "# #Optional function\n",
        "# def createAudio(spectrogram, audiosr=16000, winLength=0.05, frameshift=0.01):\n",
        "#     mfb = mel.MelFilterBank(int((audiosr*winLength)/2+1), spectrogram.shape[1], audiosr)\n",
        "#     nfolds = 10\n",
        "#     hop = int(spectrogram.shape[0]/nfolds)\n",
        "#     rec_audio = np.array([])\n",
        "#     for_reconstruction = mfb.fromLogMels(spectrogram)\n",
        "#     for w in range(0,spectrogram.shape[0],hop):\n",
        "#         spec = for_reconstruction[w:min(w+hop,for_reconstruction.shape[0]),:]\n",
        "#         rec = rW.reconstructWavFromSpectrogram(spec,spec.shape[0]*spec.shape[1],fftsize=int(audiosr*winLength),overlap=int(winLength/frameshift))\n",
        "#         rec_audio = np.append(rec_audio,rec)\n",
        "#     scaled = np.int16(rec_audio/np.max(np.abs(rec_audio)) * 32767)\n",
        "#     return scaled\n",
        "\n",
        "\n",
        "##### MODELING ########\n",
        "\n",
        "model = True\n",
        "\n",
        "scores= []\n",
        "\n",
        "if model == True:\n",
        "    feat_path = r'/content/drive/MyDrive/DeepLearning/features'\n",
        "    result_path = r'/content/drive/MyDrive/DeepLearning/features'\n",
        "    pts = ['sub-%02d'%i for i in range(1,11)]\n",
        "\n",
        "    winLength = 0.05\n",
        "    frameshift = 0.01\n",
        "    audiosr = 16000\n",
        "\n",
        "    nfolds = 15\n",
        "    kf = KFold(nfolds,shuffle=False)\n",
        "    pca = PCA()\n",
        "    numComps = 400\n",
        "    \n",
        "    #Initialize empty matrices for correlation results, randomized controls and amount of explained variance\n",
        "    allRes = np.zeros((len(pts),nfolds,23))\n",
        "    explainedVariance = np.zeros((len(pts),nfolds))\n",
        "    numRands = 1000\n",
        "    randomControl = np.zeros((len(pts),numRands, 23))\n",
        "\n",
        "    for pNr, pt in enumerate(pts):\n",
        "        \n",
        "        \n",
        "        #Load the data\n",
        "        #Dimensions of these data vary depending on the subject\n",
        "        spectrogram = np.load(os.path.join(feat_path,f'{pt}_spec.npy'))  \n",
        "        data = np.load(os.path.join(feat_path,f'{pt}_feat.npy'))\n",
        "        labels = np.load(os.path.join(feat_path,f'{pt}_procWords.npy'))\n",
        "        featName = np.load(os.path.join(feat_path,f'{pt}_feat_names.npy'))\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "        #Initialize an empty spectrogram to save the reconstruction to\n",
        "        rec_spec = np.zeros(spectrogram.shape)\n",
        "        #Save the correlation coefficients for each fold\n",
        "        rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "        for k,(train, test) in enumerate(kf.split(data)):\n",
        "          \n",
        "            #Normalization\n",
        "            mu=np.mean(data[train,:],axis=0)\n",
        "            std=np.std(data[train,:],axis=0)\n",
        "            trainData=(data[train,:]-mu)/std\n",
        "            testData=(data[test,:]-mu)/std\n",
        "\n",
        "            #Fit PCA to training data\n",
        "            pca.fit(trainData)\n",
        "            #Get percentage of explained variance by selected components\n",
        "            explainedVariance[pNr,k] = np.sum(pca.explained_variance_ratio_[:numComps])\n",
        "            #Tranform data into component space\n",
        "            trainData = np.dot(trainData, pca.components_[:numComps,:].T)\n",
        "            testData = np.dot(testData, pca.components_[:numComps,:].T)\n",
        "\n",
        "            early_stopping=EarlyStopping(patience=25, verbose=0, min_delta=1e-5)\n",
        "            checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=0)\n",
        "\n",
        "            #Autoencoder\n",
        "            model = create_ae_model(trainData.shape[1], spectrogram.shape[1])\n",
        "            model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "            model.fit(trainData, spectrogram[train, :], batch_size=64, \n",
        "                      epochs=500, verbose=0, validation_split=1/9, shuffle=True,\n",
        "                      callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "            #predict with the Autoencoder\n",
        "            rec_spec[test, :] = model.predict(testData, verbose=0)\n",
        "\n",
        "            #Evaluate reconstruction of this fold\n",
        "            for specBin in range(spectrogram.shape[1]):\n",
        "                if np.any(np.isnan(rec_spec)):\n",
        "                    print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "                r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "                rs[k,specBin] = r\n",
        "\n",
        "        #Show evaluation result\n",
        "        print('%s has mean correlation of %f' % (pt, np.mean(rs)))\n",
        "        allRes[pNr,:,:]=rs\n",
        "        scores.append(np.mean(rs))\n",
        "\n",
        "#         #Estimate random baseline\n",
        "#         for randRound in range(numRands):\n",
        "#             #Choose a random splitting point at least 10% of the dataset size away\n",
        "#             splitPoint = np.random.choice(np.arange(int(spectrogram.shape[0]*0.1),int(spectrogram.shape[0]*0.9)))\n",
        "#             #Swap the dataset on the splitting point \n",
        "#             shuffled = np.concatenate((spectrogram[splitPoint:,:],spectrogram[:splitPoint,:]))\n",
        "#             #Calculate the correlations\n",
        "#             for specBin in range(spectrogram.shape[1]):\n",
        "#                 if np.any(np.isnan(rec_spec)):\n",
        "#                     print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "#                 r, p = pearsonr(spectrogram[:,specBin], shuffled[:,specBin])\n",
        "#                 randomControl[pNr, randRound,specBin]=r\n",
        "\n",
        "\n",
        "#         #Save reconstructed spectrogram\n",
        "#         os.makedirs(os.path.join(result_path), exist_ok=True)\n",
        "#         np.save(os.path.join(result_path,f'{pt}_predicted_spec.npy'), rec_spec)\n",
        "        \n",
        "#         #Synthesize waveform from spectrogram using Griffin-Lim\n",
        "#         reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "#         wavfile.write(os.path.join(result_path,f'{pt}_predicted.wav'),int(audiosr),reconstructedWav)\n",
        "\n",
        "#         #For comparison synthesize the original spectrogram with Griffin-Lim\n",
        "#         origWav = createAudio(spectrogram,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "#         wavfile.write(os.path.join(result_path,f'{pt}_orig_synthesized.wav'),int(audiosr),origWav)\n",
        "\n",
        "#     #Save results in numpy arrays          \n",
        "#     np.save(os.path.join(result_path,'linearResults.npy'),allRes)\n",
        "#     np.save(os.path.join(result_path,'randomResults.npy'),randomControl)\n",
        "#     np.save(os.path.join(result_path,'explainedVariance.npy'),explainedVariance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a6e6b40",
      "metadata": {
        "id": "0a6e6b40",
        "outputId": "4e3b10f6-a443-47ac-e2b6-c6eba396472d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5629875535958715,\n",
              " 0.615317710223286,\n",
              " 0.8574981748428402,\n",
              " 0.816490556136459,\n",
              " 0.5712122543230624,\n",
              " 0.8819938942481294,\n",
              " 0.7771201475020989,\n",
              " 0.6878816278290169,\n",
              " 0.7386449014724298,\n",
              " 0.7146618900721041]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6FcMJWfW_99"
      },
      "id": "R6FcMJWfW_99",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}