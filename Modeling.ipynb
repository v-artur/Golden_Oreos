{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/v-artur/Golden_Oreos/blob/main/Modeling.ipynb)"
      ],
      "metadata": {
        "id": "-YwF9Hzt2euf"
      },
      "id": "-YwF9Hzt2euf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2005cbc",
      "metadata": {
        "id": "a2005cbc",
        "outputId": "5d61f399-3213-4e41-e4dc-a91589c9c4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.1.1-py3-none-any.whl (7.5 MB)\n",
            "Requirement already satisfied: tqdm in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (4.62.3)\n",
            "Requirement already satisfied: decorator in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (5.1.0)\n",
            "Collecting pooch>=1.5\n",
            "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (21.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (1.21.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (1.7.1)\n",
            "Requirement already satisfied: jinja2 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (3.0.1)\n",
            "Requirement already satisfied: matplotlib in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from mne) (3.4.3)\n",
            "Collecting appdirs>=1.3.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from packaging->mne) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from matplotlib->mne) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from matplotlib->mne) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from matplotlib->mne) (8.3.2)\n",
            "Requirement already satisfied: six in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from cycler>=0.10->matplotlib->mne) (1.16.0)\n",
            "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\otthoni\\lib\\site-packages (from tqdm->mne) (0.4.4)\n",
            "Installing collected packages: appdirs, pooch, mne\n",
            "Successfully installed appdirs-1.4.4 mne-1.1.1 pooch-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "!pip install -U pynwb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccdd92a6",
      "metadata": {
        "id": "ccdd92a6"
      },
      "source": [
        "# Ez  cella annyira nem érdekes, de érdemes lehet ránézni\n",
        "Ez a cella alapvetően a feature extraction-höz kell, de egyrészt elég alapos, másrészt nem értek hozzá, úgyhogy nem nagyon érdemes változtatgatni (esetleg később ha okosabbak leszünk).\n",
        "\n",
        "Ez létrehoz egy features nevű mappát a home directory-ba, ami minden alanynál tartalmaz egy hangfile-t, feature táblát, a feature-ök nevét tartalmazó array-t, az adott szekvenciához tartozó szavak egy array-ét illetve a spektrogram-ot (lásd a cella alsó négy sorát)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a210f4",
      "metadata": {
        "id": "60a210f4",
        "outputId": "4ed7e25e-7c45-49cb-ef6e-bf6358352b02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DONT~1\\AppData\\Local\\Temp/ipykernel_5112/789610502.py:131: DeprecationWarning: scipy.hanning is deprecated and will be removed in SciPy 2.0.0, use numpy.hanning instead\n",
            "  win = scipy.hanning(np.floor(windowLength*sr + 1))[:-1]\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import numpy.matlib as matlib\n",
        "import scipy\n",
        "import scipy.signal\n",
        "import scipy.stats\n",
        "import scipy.io.wavfile\n",
        "import scipy.fftpack\n",
        "\n",
        "from pynwb import NWBHDF5IO\n",
        "import MelFilterBank as mel\n",
        "\n",
        "#Small helper function to speed up the hilbert transform by extending the length of data to the next power of 2\n",
        "hilbert3 = lambda x: scipy.signal.hilbert(x, scipy.fftpack.next_fast_len(len(x)),axis=0)[:len(x)]\n",
        "\n",
        "def extractHG(data, sr, windowLength=0.05, frameshift=0.01):\n",
        "    \"\"\"\n",
        "    Window data and extract frequency-band envelope using the hilbert transform\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data: array (samples, channels)\n",
        "        EEG time series\n",
        "    sr: int\n",
        "        Sampling rate of the data\n",
        "    windowLength: float\n",
        "        Length of window (in seconds) in which spectrogram will be calculated\n",
        "    frameshift: float\n",
        "        Shift (in seconds) after which next window will be extracted\n",
        "    Returns\n",
        "    ----------\n",
        "    feat: array (windows, channels)\n",
        "        Frequency-band feature matrix\n",
        "    \"\"\"\n",
        "    #Linear detrend\n",
        "    data = scipy.signal.detrend(data,axis=0)\n",
        "    #Number of windows\n",
        "    numWindows = int(np.floor((data.shape[0]-windowLength*sr)/(frameshift*sr)))\n",
        "    #Filter High-Gamma Band\n",
        "    sos = scipy.signal.iirfilter(4, [70/(sr/2),170/(sr/2)],btype='bandpass',output='sos')\n",
        "    data = scipy.signal.sosfiltfilt(sos,data,axis=0)\n",
        "    #Attenuate first harmonic of line noise\n",
        "    sos = scipy.signal.iirfilter(4, [98/(sr/2),102/(sr/2)],btype='bandstop',output='sos')\n",
        "    data = scipy.signal.sosfiltfilt(sos,data,axis=0)\n",
        "    #Attenuate second harmonic of line noise\n",
        "    sos = scipy.signal.iirfilter(4, [148/(sr/2),152/(sr/2)],btype='bandstop',output='sos')\n",
        "    data = scipy.signal.sosfiltfilt(sos,data,axis=0)\n",
        "    #Create feature space\n",
        "    data = np.abs(hilbert3(data))\n",
        "    feat = np.zeros((numWindows,data.shape[1]))\n",
        "    for win in range(numWindows):\n",
        "        start= int(np.floor((win*frameshift)*sr))\n",
        "        stop = int(np.floor(start+windowLength*sr))\n",
        "        feat[win,:] = np.mean(data[start:stop,:],axis=0)\n",
        "    return feat\n",
        "\n",
        "def stackFeatures(features, modelOrder=4, stepSize=5):\n",
        "    \"\"\"\n",
        "    Add temporal context to each window by stacking neighboring feature vectors\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    features: array (windows, channels)\n",
        "        Feature time series\n",
        "    modelOrder: int\n",
        "        Number of temporal context to include prior to and after current window\n",
        "    stepSize: float\n",
        "        Number of temporal context to skip for each next context (to compensate for frameshift)\n",
        "    Returns\n",
        "    ----------\n",
        "    featStacked: array (windows, feat*(2*modelOrder+1))\n",
        "        Stacked feature matrix\n",
        "    \"\"\"\n",
        "    featStacked=np.zeros((features.shape[0]-(2*modelOrder*stepSize),(2*modelOrder+1)*features.shape[1]))\n",
        "    for fNum,i in enumerate(range(modelOrder*stepSize,features.shape[0]-modelOrder*stepSize)):\n",
        "        ef=features[i-modelOrder*stepSize:i+modelOrder*stepSize+1:stepSize,:]\n",
        "        featStacked[fNum,:]=ef.flatten() #Add 'F' if stacked the same as matlab\n",
        "    return featStacked\n",
        "\n",
        "def downsampleLabels(labels, sr, windowLength=0.05, frameshift=0.01):\n",
        "    \"\"\"\n",
        "    Downsamples non-numerical data by using the mode\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    labels: array of str\n",
        "        Label time series\n",
        "    sr: int\n",
        "        Sampling rate of the data\n",
        "    windowLength: float\n",
        "        Length of window (in seconds) in which mode will be used\n",
        "    frameshift: float\n",
        "        Shift (in seconds) after which next window will be extracted\n",
        "    Returns\n",
        "    ----------\n",
        "    newLabels: array of str\n",
        "        Downsampled labels\n",
        "    \"\"\"\n",
        "    numWindows=int(np.floor((labels.shape[0]-windowLength*sr)/(frameshift*sr)))\n",
        "    newLabels = np.empty(numWindows, dtype=\"S15\")\n",
        "    for w in range(numWindows):\n",
        "        start = int(np.floor((w*frameshift)*sr))\n",
        "        stop = int(np.floor(start+windowLength*sr))\n",
        "        newLabels[w]=scipy.stats.mode(labels[start:stop])[0][0].encode(\"ascii\", errors=\"ignore\").decode()\n",
        "    return newLabels\n",
        "\n",
        "def extractMelSpecs(audio, sr, windowLength=0.05, frameshift=0.01):\n",
        "    \"\"\"\n",
        "    Extract logarithmic mel-scaled spectrogram, traditionally used to compress audio spectrograms\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    audio: array\n",
        "        Audio time series\n",
        "    sr: int\n",
        "        Sampling rate of the audio\n",
        "    windowLength: float\n",
        "        Length of window (in seconds) in which spectrogram will be calculated\n",
        "    frameshift: float\n",
        "        Shift (in seconds) after which next window will be extracted\n",
        "    numFilter: int\n",
        "        Number of triangular filters in the mel filterbank\n",
        "    Returns\n",
        "    ----------\n",
        "    spectrogram: array (numWindows, numFilter)\n",
        "        Logarithmic mel scaled spectrogram\n",
        "    \"\"\"\n",
        "    numWindows=int(np.floor((audio.shape[0]-windowLength*sr)/(frameshift*sr)))\n",
        "    win = np.hanning(np.floor(windowLength*sr + 1))[:-1]\n",
        "    spectrogram = np.zeros((numWindows, int(np.floor(windowLength*sr / 2 + 1))),dtype='complex')\n",
        "    for w in range(numWindows):\n",
        "        start_audio = int(np.floor((w*frameshift)*sr))\n",
        "        stop_audio = int(np.floor(start_audio+windowLength*sr))\n",
        "        a = audio[start_audio:stop_audio]\n",
        "        spec = np.fft.rfft(win*a)\n",
        "        spectrogram[w,:] = spec\n",
        "    mfb = mel.MelFilterBank(spectrogram.shape[1], 23, sr)\n",
        "    spectrogram = np.abs(spectrogram)\n",
        "    spectrogram = (mfb.toLogMels(spectrogram)).astype('float')\n",
        "    return spectrogram\n",
        "\n",
        "def nameVector(elecs, modelOrder=4):\n",
        "    \"\"\"\n",
        "    Creates list of electrode names\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    elecs: array of str\n",
        "        Original electrode names\n",
        "    modelOrder: int\n",
        "        Temporal context stacked prior and after current window\n",
        "        Will be added as T-modelOrder, T-(modelOrder+1), ...,  T0, ..., T+modelOrder\n",
        "        to the elctrode names\n",
        "    Returns\n",
        "    ----------\n",
        "    names: array of str\n",
        "        List of electrodes including contexts, will have size elecs.shape[0]*(2*modelOrder+1)\n",
        "    \"\"\"\n",
        "    names = matlib.repmat(elecs.astype(np.dtype(('U', 10))),1,2 * modelOrder +1).T\n",
        "    for i, off in enumerate(range(-modelOrder,modelOrder+1)):\n",
        "        names[i,:] = [e[0] + 'T' + str(off) for e in elecs]\n",
        "    return names.flatten()  #Add 'F' if stacked the same as matlab\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    winL = 0.05\n",
        "    frameshift = 0.01\n",
        "    modelOrder = 4\n",
        "    stepSize = 5\n",
        "    path_bids = r'./SingleWordProductionDutch-iBIDS'\n",
        "    path_output = r'./features'\n",
        "    participants = pd.read_csv(os.path.join(path_bids,'participants.tsv'), delimiter='\\t')\n",
        "    for p_id, participant in enumerate(participants['participant_id']):\n",
        "        \n",
        "        #Load data\n",
        "        io = NWBHDF5IO(os.path.join(path_bids,participant,'ieeg',f'{participant}_task-wordProduction_ieeg.nwb'), 'r')\n",
        "        nwbfile = io.read()\n",
        "        #sEEG\n",
        "        eeg = nwbfile.acquisition['iEEG'].data[:]\n",
        "        eeg_sr = 1024\n",
        "        #audio\n",
        "        audio = nwbfile.acquisition['Audio'].data[:]\n",
        "        audio_sr = 48000\n",
        "        #words (markers)\n",
        "        words = nwbfile.acquisition['Stimulus'].data[:]\n",
        "        words = np.array(words, dtype=str)\n",
        "        io.close()\n",
        "        #channels\n",
        "        channels = pd.read_csv(os.path.join(path_bids,participant,'ieeg',f'{participant}_task-wordProduction_channels.tsv'), delimiter='\\t')\n",
        "        channels = np.array(channels['name'])\n",
        "\n",
        "        #Extract HG features\n",
        "        feat = extractHG(eeg,eeg_sr, windowLength=winL,frameshift=frameshift)\n",
        "\n",
        "        #Stack features\n",
        "        feat = stackFeatures(feat,modelOrder=modelOrder,stepSize=stepSize)\n",
        "        \n",
        "        #Process Audio\n",
        "        target_SR = 16000\n",
        "        audio = scipy.signal.decimate(audio,int(audio_sr / target_SR))\n",
        "        audio_sr = target_SR\n",
        "        scaled = np.int16(audio/np.max(np.abs(audio)) * 32767)\n",
        "        os.makedirs(os.path.join(path_output), exist_ok=True)\n",
        "        scipy.io.wavfile.write(os.path.join(path_output,f'{participant}_orig_audio.wav'),audio_sr,scaled)   \n",
        "\n",
        "        #Extract spectrogram\n",
        "        melSpec = extractMelSpecs(scaled,audio_sr,windowLength=winL,frameshift=frameshift)\n",
        "        \n",
        "        #Align to EEG features\n",
        "        melSpec = melSpec[modelOrder*stepSize:melSpec.shape[0]-modelOrder*stepSize,:]\n",
        "        #adjust length (differences might occur due to rounding in the number of windows)\n",
        "        if melSpec.shape[0]!=feat.shape[0]:\n",
        "            tLen = np.min([melSpec.shape[0],feat.shape[0]])\n",
        "            melSpec = melSpec[:tLen,:]\n",
        "            feat = feat[:tLen,:]\n",
        "        \n",
        "        #Create feature names by appending the temporal shift \n",
        "        feature_names = nameVector(channels[:,None], modelOrder=modelOrder)\n",
        "\n",
        "        #Save everything\n",
        "        np.save(os.path.join(path_output,f'{participant}_feat.npy'), feat)\n",
        "        np.save(os.path.join(path_output,f'{participant}_procWords.npy'), words)\n",
        "        np.save(os.path.join(path_output,f'{participant}_spec.npy'), melSpec)\n",
        "        np.save(os.path.join(path_output,f'{participant}_feat_names.npy'), feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c0796a",
      "metadata": {
        "id": "31c0796a",
        "outputId": "14c1d770-7fbe-4e5d-ce35-6dd789010181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sub-01 has mean correlation of 0.519977\n",
            "sub-02 has mean correlation of 0.632364\n",
            "sub-03 has mean correlation of 0.837003\n",
            "sub-04 has mean correlation of 0.780109\n",
            "sub-05 has mean correlation of 0.532358\n",
            "sub-06 has mean correlation of 0.861970\n",
            "sub-07 has mean correlation of 0.707043\n",
            "sub-08 has mean correlation of 0.715179\n",
            "sub-09 has mean correlation of 0.657480\n",
            "sub-10 has mean correlation of 0.692957\n"
          ]
        }
      ],
      "source": [
        "# Reconstruction\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wavfile\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import reconstructWave as rW\n",
        "import MelFilterBank as mel\n",
        "\n",
        "\n",
        "def createAudio(spectrogram, audiosr=16000, winLength=0.05, frameshift=0.01):\n",
        "    \"\"\"\n",
        "    Create a reconstructed audio wavefrom\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    spectrogram: array\n",
        "        Spectrogram of the audio\n",
        "    sr: int\n",
        "        Sampling rate of the audio\n",
        "    windowLength: float\n",
        "        Length of window (in seconds) in which spectrogram was calculated\n",
        "    frameshift: float\n",
        "        Shift (in seconds) after which next window was extracted\n",
        "    Returns\n",
        "    ----------\n",
        "    scaled: array\n",
        "        Scaled audio waveform\n",
        "    \"\"\"\n",
        "    mfb = mel.MelFilterBank(int((audiosr*winLength)/2+1), spectrogram.shape[1], audiosr)\n",
        "    nfolds = 10\n",
        "    hop = int(spectrogram.shape[0]/nfolds)\n",
        "    rec_audio = np.array([])\n",
        "    for_reconstruction = mfb.fromLogMels(spectrogram)\n",
        "    for w in range(0,spectrogram.shape[0],hop):\n",
        "        spec = for_reconstruction[w:min(w+hop,for_reconstruction.shape[0]),:]\n",
        "        rec = rW.reconstructWavFromSpectrogram(spec,spec.shape[0]*spec.shape[1],fftsize=int(audiosr*winLength),overlap=int(winLength/frameshift))\n",
        "        rec_audio = np.append(rec_audio,rec)\n",
        "    scaled = np.int16(rec_audio/np.max(np.abs(rec_audio)) * 32767)\n",
        "    return scaled\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    feat_path = r'./features'\n",
        "    result_path = r'./results'\n",
        "    pts = ['sub-%02d'%i for i in range(1,11)]\n",
        "\n",
        "    winLength = 0.05\n",
        "    frameshift = 0.01\n",
        "    audiosr = 16000\n",
        "\n",
        "    nfolds = 10\n",
        "    kf = KFold(nfolds,shuffle=False)\n",
        "    est = LinearRegression(n_jobs=5)\n",
        "    pca = PCA()\n",
        "    numComps = 50\n",
        "    \n",
        "    #Initialize empty matrices for correlation results, randomized contols and amount of explained variance\n",
        "    allRes = np.zeros((len(pts),nfolds,23))\n",
        "    explainedVariance = np.zeros((len(pts),nfolds))\n",
        "    numRands = 1000\n",
        "    randomControl = np.zeros((len(pts),numRands, 23))\n",
        "\n",
        "    for pNr, pt in enumerate(pts):\n",
        "        \n",
        "        \n",
        "        #Load the data\n",
        "        #Dimensions of these data vary depending on the subject\n",
        "        spectrogram = np.load(os.path.join(feat_path,f'{pt}_spec.npy'))  \n",
        "        data = np.load(os.path.join(feat_path,f'{pt}_feat.npy'))\n",
        "        labels = np.load(os.path.join(feat_path,f'{pt}_procWords.npy'))\n",
        "        featName = np.load(os.path.join(feat_path,f'{pt}_feat_names.npy'))\n",
        "        \n",
        "        #Initialize an empty spectrogram to save the reconstruction to\n",
        "        rec_spec = np.zeros(spectrogram.shape)\n",
        "        #Save the correlation coefficients for each fold\n",
        "        rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "        for k,(train, test) in enumerate(kf.split(data)):\n",
        "            #Z-Normalize with mean and std from the training data\n",
        "            mu=np.mean(data[train,:],axis=0)\n",
        "            std=np.std(data[train,:],axis=0)\n",
        "            trainData=(data[train,:]-mu)/std\n",
        "            testData=(data[test,:]-mu)/std\n",
        "\n",
        "            #Fit PCA to training data\n",
        "            pca.fit(trainData)\n",
        "            #Get percentage of explained variance by selected components\n",
        "            explainedVariance[pNr,k] =  np.sum(pca.explained_variance_ratio_[:numComps])\n",
        "            #Tranform data into component space\n",
        "            trainData=np.dot(trainData, pca.components_[:numComps,:].T)\n",
        "            testData = np.dot(testData, pca.components_[:numComps,:].T)\n",
        "            \n",
        "            #Fit the regression model\n",
        "            est.fit(trainData, spectrogram[train, :])\n",
        "            #Predict the reconstructed spectrogram for the test data\n",
        "            rec_spec[test, :] = est.predict(testData)\n",
        "\n",
        "            #Evaluate reconstruction of this fold\n",
        "            for specBin in range(spectrogram.shape[1]):\n",
        "                if np.any(np.isnan(rec_spec)):\n",
        "                    print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "                r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "                rs[k,specBin] = r\n",
        "\n",
        "        #Show evaluation result\n",
        "        print('%s has mean correlation of %f' % (pt, np.mean(rs)))\n",
        "        allRes[pNr,:,:]=rs\n",
        "\n",
        "        #Estimate random baseline\n",
        "        for randRound in range(numRands):\n",
        "            #Choose a random splitting point at least 10% of the dataset size away\n",
        "            splitPoint = np.random.choice(np.arange(int(spectrogram.shape[0]*0.1),int(spectrogram.shape[0]*0.9)))\n",
        "            #Swap the dataset on the splitting point \n",
        "            shuffled = np.concatenate((spectrogram[splitPoint:,:],spectrogram[:splitPoint,:]))\n",
        "            #Calculate the correlations\n",
        "            for specBin in range(spectrogram.shape[1]):\n",
        "                if np.any(np.isnan(rec_spec)):\n",
        "                    print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "                r, p = pearsonr(spectrogram[:,specBin], shuffled[:,specBin])\n",
        "                randomControl[pNr, randRound,specBin]=r\n",
        "\n",
        "\n",
        "        #Save reconstructed spectrogram\n",
        "        os.makedirs(os.path.join(result_path), exist_ok=True)\n",
        "        np.save(os.path.join(result_path,f'{pt}_predicted_spec.npy'), rec_spec)\n",
        "        \n",
        "        #Synthesize waveform from spectrogram using Griffin-Lim\n",
        "        reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "        wavfile.write(os.path.join(result_path,f'{pt}_predicted.wav'),int(audiosr),reconstructedWav)\n",
        "\n",
        "        #For comparison synthesize the original spectrogram with Griffin-Lim\n",
        "        origWav = createAudio(spectrogram,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "        wavfile.write(os.path.join(result_path,f'{pt}_orig_synthesized.wav'),int(audiosr),origWav)\n",
        "\n",
        "    #Save results in numpy arrays          \n",
        "    np.save(os.path.join(result_path,'linearResults.npy'),allRes)\n",
        "    np.save(os.path.join(result_path,'randomResults.npy'),randomControl)\n",
        "    np.save(os.path.join(result_path,'explainedVariance.npy'),explainedVariance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6e6b40",
      "metadata": {
        "id": "0a6e6b40"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}