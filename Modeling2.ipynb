{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/v-artur/Golden_Oreos/blob/main/Modeling2.ipynb)"
      ],
      "metadata": {
        "id": "-YwF9Hzt2euf"
      },
      "id": "-YwF9Hzt2euf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install some of the dependencies"
      ],
      "metadata": {
        "id": "cQlwBAw2thv5"
      },
      "id": "cQlwBAw2thv5"
    },
    {
      "cell_type": "code",
      "source": [
        "# if mcd does not work, fastdtw and pystpk are not needed\n",
        "!pip install fastdtw\n",
        "!pip install pysptk\n",
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqZPdDbxtfjo",
        "outputId": "816bce73-02cd-4090-9953-a6e769997151"
      },
      "id": "JqZPdDbxtfjo",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastdtw) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pysptk\n",
            "  Downloading pysptk-0.2.0.tar.gz (276 kB)\n",
            "\u001b[K     |████████████████████████████████| 276 kB 5.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from pysptk) (0.29.32)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from pysptk) (4.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pysptk) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->pysptk) (1.21.6)\n",
            "Building wheels for collected packages: pysptk\n",
            "  Building wheel for pysptk (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysptk: filename=pysptk-0.2.0-cp37-cp37m-linux_x86_64.whl size=931381 sha256=ca8ac1c9f4d2620607ba2562aa93adc777171929c877293246dd4b48ca6e83eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/70/a1/757bd6c0017f384831e6260a784f10ff6d7998a805719f9a2d\n",
            "Successfully built pysptk\n",
            "Installing collected packages: pysptk\n",
            "Successfully installed pysptk-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import files from Google drive"
      ],
      "metadata": {
        "id": "gVCNOaaoDSbO"
      },
      "id": "gVCNOaaoDSbO"
    },
    {
      "cell_type": "code",
      "source": [
        "#the data\n",
        "!gdown https://drive.google.com/uc?id=1vtZchVzl424pSQBXQ8EBxvVOzcEQPKIp\n",
        "#reconstruction module\n",
        "!gdown https://drive.google.com/u/0/uc?id=1KYJD7INBZJ4Wip_ok6nGaJNGHZOCl8ra\n",
        "#Melfiltebank applier\n",
        "!gdown https://drive.google.com/u/0/uc?id=16XwS13GUAa7HuJv1Yi1XP6lQm0Gz42Ho\n",
        "\n",
        "#extract the zip\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/features.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/features\")\n",
        "zip_ref.close()\n",
        "\n",
        "#creating a folder for the synthesized audio\n",
        "!mkdir synth_audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp52U4pNltAZ",
        "outputId": "31750b3c-b9d0-4d41-a624-56d06c345bb6"
      },
      "id": "jp52U4pNltAZ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vtZchVzl424pSQBXQ8EBxvVOzcEQPKIp\n",
            "To: /content/features.zip\n",
            "100% 2.14G/2.14G [00:18<00:00, 117MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1KYJD7INBZJ4Wip_ok6nGaJNGHZOCl8ra\n",
            "To: /content/reconstructWave.py\n",
            "100% 3.02k/3.02k [00:00<00:00, 4.78MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=16XwS13GUAa7HuJv1Yi1XP6lQm0Gz42Ho\n",
            "To: /content/MelFilterBank.py\n",
            "100% 2.87k/2.87k [00:00<00:00, 4.71MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necessary models and functions"
      ],
      "metadata": {
        "id": "QUch8ZTsGET3"
      },
      "id": "QUch8ZTsGET3"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, GRU, Conv1D, MaxPooling1D, Flatten, TimeDistributed\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Bottleneck FC-DNN\n",
        "\n",
        "def create_bottleneck_model(inputsize, outputsize):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(inputsize)))\n",
        "    model.add(tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(4, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(16, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(outputsize))\n",
        "    return model\n",
        "\n",
        "#Normal FC-DNN\n",
        "\n",
        "def create_dnn_model(inputsize, outputsize):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(inputsize)))\n",
        "    model.add(tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer='HeNormal'))\n",
        "    model.add(tf.keras.layers.Dropout(0.2))\n",
        "    model.add(tf.keras.layers.Dense(outputsize))\n",
        "    return model\n",
        "\n",
        "\n",
        "#LSTM/GRU Network\n",
        "\n",
        "def create_LSTM_model(inputsize, outputsize):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(LSTM(units=300, dropout=0.2, return_sequences=True, input_shape=(inputsize,1)))\n",
        "  model.add(LSTM(units=300, dropout=0.2, return_sequences=True, input_shape=(inputsize,1)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(outputsize))\n",
        "  return(model)\n",
        "\n",
        "\n",
        "#CNN network\n",
        "\n",
        "def create_cnn_model(rows_per_feature, cols_per_feature, outputsize):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(Conv1D(10, 8, activation=\"relu\", input_shape=(rows_per_feature, cols_per_feature,)))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(10, 20, activation=\"relu\"))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=outputsize, activation='linear'))\n",
        "  return(model)\n",
        "\n",
        "\n",
        "#Function to make a 2D object out of the EEG featurevector with sliding window\n",
        "#windowsize is minimum 10 and multiple of 2.\n",
        "def cnnize(data, window):\n",
        "  data = np.asarray(data)\n",
        "  #the new array, the first coordinate is the number of samples,\n",
        "  #the second and the third are the new features\n",
        "  X = np.zeros((data.shape[0], int((data.shape[1]-window)/2)+1 , window))\n",
        "  for index, elem in enumerate(data):\n",
        "    # creating the feature-parts\n",
        "    new_elems = np.array([elem[i:i+window] for i in range(0, data.shape[1] - window + 1, 2)])\n",
        "    X[index] = new_elems\n",
        "  return X\n",
        "\n",
        "\n",
        "#Reconstructing the WAV file from the predicted mel-log spectrogram (Griffin-Lim method)\n",
        "\n",
        "def createAudio(spectrogram, audiosr=16000, winLength=0.05, frameshift=0.01):\n",
        "    mfb = mel.MelFilterBank(int((audiosr*winLength)/2+1), spectrogram.shape[1], audiosr)\n",
        "    nfolds = 10\n",
        "    hop = int(spectrogram.shape[0]/nfolds)\n",
        "    rec_audio = np.array([])\n",
        "    for_reconstruction = mfb.fromLogMels(spectrogram)\n",
        "    for w in range(0,spectrogram.shape[0],hop):\n",
        "        spec = for_reconstruction[w:min(w+hop,for_reconstruction.shape[0]),:]\n",
        "        rec = rW.reconstructWavFromSpectrogram(spec,spec.shape[0]*spec.shape[1],fftsize=int(audiosr*winLength),overlap=int(winLength/frameshift))\n",
        "        rec_audio = np.append(rec_audio,rec)\n",
        "    scaled = np.int16(rec_audio/np.max(np.abs(rec_audio)) * 32767)\n",
        "    return scaled\n",
        "\n"
      ],
      "metadata": {
        "id": "c_ucdMo6hCjq"
      },
      "id": "c_ucdMo6hCjq",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For audio reconstruction and MCD measure \n",
        "#dependencies\n",
        "import reconstructWave as rW\n",
        "import MelFilterBank as mel\n",
        "import numpy as np\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import pysptk\n",
        "from scipy.spatial.distance import euclidean\n",
        "import os\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "# functions for MCD calculations \n",
        "# (source: https://github.com/ttslr/python-MCD?fbclid=IwAR2OFaz3-8kTfhJXC7F-cmTTHkY-egEzZdSYHsC0agwPw58N2G3hqhfdVNY)\n",
        "\n",
        "natural_folder = '/content/features/'\n",
        "synth_folder = '/content/synth_audio/' \n",
        "\n",
        "\n",
        "def readmgc(filename):\n",
        "    sr, x = wavfile.read(filename)\n",
        "    assert sr == 16000\n",
        "    x = x.astype(np.float64)\n",
        "    frame_length = 1024\n",
        "    hop_length = 256  \n",
        "    frames = librosa.util.frame(x, frame_length=frame_length, hop_length=hop_length).astype(np.float64).T\n",
        "    frames *= pysptk.blackman(frame_length)\n",
        "    assert frames.shape[1] == frame_length \n",
        "    order = 25\n",
        "    alpha = 0.41\n",
        "    stage = 5\n",
        "    gamma = -1.0 / stage\n",
        "\n",
        "    mgc = pysptk.mgcep(frames, order, alpha, gamma)\n",
        "    mgc = mgc.reshape(-1, order + 1)\n",
        "    print(\"mgc of {} is ok!\".format(filename))\n",
        "    return mgc\n",
        "\n",
        "\n",
        "def compute_mcd():\n",
        "\n",
        "  #computational parameters\n",
        "  _logdb_const = 10.0 / np.log(10.0) * np.sqrt(2.0)\n",
        "  s = 0.0\n",
        "  framesTot = 0\n",
        "\n",
        "  # computing the MCD\n",
        "  files = os.listdir(synth_folder)\n",
        "  for subject in files:\n",
        "    print(\"Processing -----------{}\".format(subject))\n",
        "    \n",
        "    subject_ID = subject[0:7]\n",
        "    \n",
        "    filename1 = natural_folder + subject_ID + 'orig_audio.wav'\n",
        "    mgc1 = readmgc(filename1)\n",
        "    filename2 = synth_folder + subject_ID + 'predicted.wav'\n",
        "    mgc2 = readmgc(filename2)\n",
        "  \n",
        "    x = mgc1\n",
        "    y = mgc2\n",
        "\n",
        "    distance, path = fastdtw(x, y, dist=euclidean)\n",
        "  \n",
        "    distance/= (len(x) + len(y))\n",
        "    pathx = list(map(lambda l: l[0], path))\n",
        "    pathy = list(map(lambda l: l[1], path))\n",
        "    x, y = x[pathx], y[pathy]\n",
        "\n",
        "    frames = x.shape[0]\n",
        "    framesTot  += frames\n",
        "\n",
        "    z = x - y\n",
        "    s += np.sqrt((z * z).sum(-1)).sum()\n",
        "\n",
        "  MCD_value = _logdb_const * float(s) / float(framesTot)\n",
        "\n",
        "  print(\"MCD = : {:f}\".format(MCD_value))\n"
      ],
      "metadata": {
        "id": "ZKmywxopiNWr"
      },
      "id": "ZKmywxopiNWr",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting seed\n",
        "tf.keras.utils.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "2qPUyWV8hC_Z"
      },
      "id": "2qPUyWV8hC_Z",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.) One person model"
      ],
      "metadata": {
        "id": "SFlhVaHrGjo-"
      },
      "id": "SFlhVaHrGjo-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing the bottleneck FC-DNN structure for one person\n",
        "\n"
      ],
      "metadata": {
        "id": "wZ5bO6U_yM5h"
      },
      "id": "wZ5bO6U_yM5h"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "\n",
        "\n",
        "data = np.load(r'/content/features/sub-01_feat.npy')\n",
        "spectrogram = np.load(r'/content/features/sub-01_spec.npy')\n",
        "\n",
        "#Inital parameters\n",
        "nfolds = 10\n",
        "kf = KFold(nfolds,shuffle=False)\n",
        "pca = PCA()\n",
        "numComps = 200\n",
        "val_split = 0.2\n",
        "\n",
        "#Audio Reconstruction parameters\n",
        "winLength = 0.05\n",
        "frameshift = 0.01\n",
        "audiosr = 16000\n",
        "\n",
        "#Initialize an empty spectrogram to save the reconstruction to\n",
        "rec_spec = np.zeros(spectrogram.shape)\n",
        "#Save the correlation coefficients for each fold\n",
        "rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "for k,(train, test) in enumerate(kf.split(data)):\n",
        "          \n",
        "    #Train, validation and test data\n",
        "    X_train_temp = data[train,:]\n",
        "    y_train_temp = spectrogram[train,:]\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=val_split, random_state=0)\n",
        "    X_test = data[test,:]\n",
        "    y_test = spectrogram[test,:] # this one might not be needed\n",
        "    \n",
        "    #Normalization\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train[:] = scaler.transform(X_train)\n",
        "    X_val[:] = scaler.transform(X_val)\n",
        "    X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "    #Fit PCA to training data\n",
        "    pca.fit(X_train)\n",
        "    #Tranform data \n",
        "    X_train = np.dot(X_train, pca.components_[:numComps,:].T)\n",
        "    X_val = np.dot(X_val, pca.components_[:numComps,:].T)\n",
        "    X_test = np.dot(X_test, pca.components_[:numComps,:].T)\n",
        "\n",
        "    # Bottleneck model\n",
        "    early_stopping=EarlyStopping(patience=25, verbose=1, min_delta=1e-5)\n",
        "    checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "    model = create_bottleneck_model(numComps, spectrogram.shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    model.fit(X_train, y_train, batch_size=64, \n",
        "              epochs=100, verbose=0, validation_data=(X_val, y_val), shuffle=True,\n",
        "              callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "    #predict with the Autoencoder\n",
        "    model.load_weights('weights1.hdf5')\n",
        "    rec_spec[test, :] = model.predict(X_test, verbose=0)\n",
        "\n",
        "    #Evaluate reconstruction of this fold\n",
        "    for specBin in range(spectrogram.shape[1]):\n",
        "         r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "         rs[k,specBin] = r\n",
        "\n",
        "\n",
        "#Show evaluation result\n",
        "print('mean correlation', np.mean(rs))\n",
        "\n",
        "#Make and save the synthesized audio\n",
        "reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "wavfile.write(os.path.join('/content/synth_audio/sub-01_predicted.wav'),int(audiosr),reconstructedWav)"
      ],
      "metadata": {
        "id": "ZHp3r8AIyUfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a195712e-bd99-4709-ba03-377f574d8a54"
      },
      "id": "ZHp3r8AIyUfI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 5.08743, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 5.08743 to 3.29884, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 3.29884 to 2.55712, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 2.55712 to 2.20429, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 2.20429 to 2.04845, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 2.04845 to 1.91544, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.91544 to 1.71705, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.71705 to 1.50765, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 1.50765 to 1.50368, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.50368\n",
            "\n",
            "Epoch 11: val_loss did not improve from 1.50368\n",
            "\n",
            "Epoch 12: val_loss improved from 1.50368 to 1.47402, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 1.47402\n",
            "\n",
            "Epoch 14: val_loss improved from 1.47402 to 1.46418, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 1.46418 to 1.38421, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 1.38421\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.38421\n",
            "\n",
            "Epoch 18: val_loss improved from 1.38421 to 1.19393, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.19393\n",
            "\n",
            "Epoch 20: val_loss did not improve from 1.19393\n",
            "\n",
            "Epoch 21: val_loss did not improve from 1.19393\n",
            "\n",
            "Epoch 22: val_loss improved from 1.19393 to 1.18906, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 1.18906\n",
            "\n",
            "Epoch 24: val_loss did not improve from 1.18906\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ab1b2aa19223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     model.fit(X_train, y_train, batch_size=64, \n\u001b[1;32m     57\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m               callbacks=[checkpointer, early_stopping])\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#predict with the Autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing the normal FC-DNN structure for one person\n"
      ],
      "metadata": {
        "id": "S9LnfCf5X5ac"
      },
      "id": "S9LnfCf5X5ac"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "\n",
        "data = np.load(r'/content/features/sub-01_feat.npy')\n",
        "spectrogram = np.load(r'/content/features/sub-01_spec.npy')\n",
        "\n",
        "#Inital parameters for prediction\n",
        "nfolds = 10\n",
        "kf = KFold(nfolds,shuffle=False)\n",
        "pca = PCA()\n",
        "numComps = 300\n",
        "val_split = 0.2\n",
        "\n",
        "#Audio Reconstruction parameters\n",
        "winLength = 0.05\n",
        "frameshift = 0.01\n",
        "audiosr = 16000\n",
        "\n",
        "\n",
        "#Initialize an empty spectrogram to save the reconstruction to\n",
        "rec_spec = np.zeros(spectrogram.shape)\n",
        "#Save the correlation coefficients for each fold\n",
        "rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "for k,(train, test) in enumerate(kf.split(data)):\n",
        "          \n",
        "    #Train, validation and test data\n",
        "    X_train_temp = data[train,:]\n",
        "    y_train_temp = spectrogram[train,:]\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=val_split, random_state=0)\n",
        "    X_test = data[test,:]\n",
        "    y_test = spectrogram[test,:] # this one might not be needed\n",
        "    \n",
        "    #Normalization\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train[:] = scaler.transform(X_train)\n",
        "    X_val[:] = scaler.transform(X_val)\n",
        "    X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "    #Fit PCA to training data\n",
        "    pca.fit(X_train)\n",
        "    #Tranform data \n",
        "    X_train = np.dot(X_train, pca.components_[:numComps,:].T)\n",
        "    X_val = np.dot(X_val, pca.components_[:numComps,:].T)\n",
        "    X_test = np.dot(X_test, pca.components_[:numComps,:].T)\n",
        "\n",
        "    # normal DNN model\n",
        "    early_stopping=EarlyStopping(patience=25, verbose=1, min_delta=1e-5)\n",
        "    checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "    model = create_dnn_model(numComps, spectrogram.shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    model.fit(X_train, y_train, batch_size=64, \n",
        "              epochs=100, verbose=0, validation_data=(X_val, y_val), shuffle=True,\n",
        "              callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "    #predict with the Autoencoder\n",
        "    model.load_weights('weights1.hdf5')\n",
        "    rec_spec[test, :] = model.predict(X_test, verbose=0)\n",
        "\n",
        "    #Evaluate reconstruction of this fold\n",
        "    for specBin in range(spectrogram.shape[1]):\n",
        "         r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "         rs[k,specBin] = r\n",
        "\n",
        "\n",
        "#Show evaluation result\n",
        "print('mean correlation', np.mean(rs))\n",
        "\n",
        "#Make and save the synthesized audio\n",
        "reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "wavfile.write(os.path.join('/content/synth_audio/','sub-01_predicted.wav'),int(audiosr),reconstructedWav)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv9hEqqcX77J",
        "outputId": "f34033bd-51cb-4351-cc68-e8b367077ba3"
      },
      "id": "hv9hEqqcX77J",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.51148, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.51148 to 1.70454, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.70454\n",
            "\n",
            "Epoch 4: val_loss improved from 1.70454 to 1.59680, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.59680 to 1.27844, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.27844 to 0.98948, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.98948\n",
            "\n",
            "Epoch 8: val_loss improved from 0.98948 to 0.86860, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.86860\n",
            "\n",
            "Epoch 10: val_loss improved from 0.86860 to 0.82983, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.82983 to 0.77544, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.77544\n",
            "\n",
            "Epoch 13: val_loss improved from 0.77544 to 0.72470, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.72470 to 0.69793, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.69793 to 0.63618, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.63618 to 0.58664, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.58664\n",
            "\n",
            "Epoch 18: val_loss improved from 0.58664 to 0.51135, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.51135\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.51135\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.51135\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.51135\n",
            "\n",
            "Epoch 23: val_loss improved from 0.51135 to 0.46329, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.46329 to 0.45925, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.45925\n",
            "\n",
            "Epoch 26: val_loss improved from 0.45925 to 0.43437, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.43437\n",
            "\n",
            "Epoch 39: val_loss improved from 0.43437 to 0.42371, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.42371\n",
            "\n",
            "Epoch 50: val_loss improved from 0.42371 to 0.40212, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.40212\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.40212\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.40212\n",
            "\n",
            "Epoch 54: val_loss improved from 0.40212 to 0.38149, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.38149\n",
            "\n",
            "Epoch 65: val_loss improved from 0.38149 to 0.36487, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.36487\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.36487\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.36487\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.36487\n",
            "\n",
            "Epoch 70: val_loss improved from 0.36487 to 0.34127, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 71: val_loss improved from 0.34127 to 0.31906, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.31906\n",
            "\n",
            "Epoch 91: val_loss improved from 0.31906 to 0.29404, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.29404\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.29404\n",
            "Epoch 116: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.55245, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.55245 to 1.71320, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss did not improve from 1.71320\n",
            "\n",
            "Epoch 4: val_loss improved from 1.71320 to 1.38651, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.38651 to 1.11558, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss did not improve from 1.11558\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.11558\n",
            "\n",
            "Epoch 8: val_loss improved from 1.11558 to 0.82204, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.82204\n",
            "\n",
            "Epoch 10: val_loss improved from 0.82204 to 0.76738, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.76738 to 0.76563, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.76563\n",
            "\n",
            "Epoch 13: val_loss improved from 0.76563 to 0.69424, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.69424\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.69424\n",
            "\n",
            "Epoch 16: val_loss improved from 0.69424 to 0.69051, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.69051\n",
            "\n",
            "Epoch 18: val_loss improved from 0.69051 to 0.55727, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.55727\n",
            "\n",
            "Epoch 25: val_loss improved from 0.55727 to 0.55378, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.55378\n",
            "\n",
            "Epoch 27: val_loss improved from 0.55378 to 0.51542, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.51542\n",
            "\n",
            "Epoch 29: val_loss improved from 0.51542 to 0.48404, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.48404\n",
            "\n",
            "Epoch 39: val_loss improved from 0.48404 to 0.47177, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.47177\n",
            "\n",
            "Epoch 41: val_loss improved from 0.47177 to 0.46777, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.46777\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.46777\n",
            "\n",
            "Epoch 44: val_loss improved from 0.46777 to 0.45600, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.45600\n",
            "\n",
            "Epoch 52: val_loss improved from 0.45600 to 0.40523, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.40523\n",
            "\n",
            "Epoch 62: val_loss improved from 0.40523 to 0.35906, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.35906\n",
            "\n",
            "Epoch 64: val_loss improved from 0.35906 to 0.33182, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.33182\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.33182\n",
            "Epoch 89: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.44761, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.44761 to 1.84474, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 1.84474 to 1.71996, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.71996 to 1.54424, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.54424 to 1.28090, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.28090 to 1.24468, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.24468 to 1.15005, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.15005 to 1.09182, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 1.09182 to 0.75818, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.75818\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.75818\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.75818\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.75818\n",
            "\n",
            "Epoch 14: val_loss improved from 0.75818 to 0.75206, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.75206 to 0.73627, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.73627 to 0.63160, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.63160 to 0.60119, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.60119\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.60119\n",
            "\n",
            "Epoch 20: val_loss improved from 0.60119 to 0.52545, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.52545\n",
            "\n",
            "Epoch 22: val_loss improved from 0.52545 to 0.46521, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss improved from 0.46521 to 0.45898, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.45898\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.45898\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.45898\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.45898\n",
            "\n",
            "Epoch 28: val_loss improved from 0.45898 to 0.44370, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 29: val_loss improved from 0.44370 to 0.43711, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.43711\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.43711\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.43711\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.43711\n",
            "\n",
            "Epoch 34: val_loss improved from 0.43711 to 0.43003, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.43003\n",
            "\n",
            "Epoch 41: val_loss improved from 0.43003 to 0.40475, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.40475\n",
            "\n",
            "Epoch 48: val_loss improved from 0.40475 to 0.36372, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.36372\n",
            "\n",
            "Epoch 59: val_loss improved from 0.36372 to 0.36044, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.36044\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.36044\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.36044\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.36044\n",
            "\n",
            "Epoch 64: val_loss improved from 0.36044 to 0.28994, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.28994\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.28994\n",
            "Epoch 89: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.34676, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.34676 to 2.17312, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 2.17312 to 1.71071, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.71071 to 1.31652, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.31652\n",
            "\n",
            "Epoch 6: val_loss improved from 1.31652 to 1.17804, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.17804 to 0.95705, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 0.95705 to 0.85174, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.85174 to 0.82428, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.82428 to 0.74643, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.74643 to 0.74181, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.74181\n",
            "\n",
            "Epoch 13: val_loss improved from 0.74181 to 0.68064, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.68064\n",
            "\n",
            "Epoch 15: val_loss improved from 0.68064 to 0.64363, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.64363\n",
            "\n",
            "Epoch 17: val_loss improved from 0.64363 to 0.59795, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.59795 to 0.54374, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.54374 to 0.49916, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.49916\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.49916\n",
            "\n",
            "Epoch 22: val_loss improved from 0.49916 to 0.48987, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.48987\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.48987\n",
            "\n",
            "Epoch 25: val_loss improved from 0.48987 to 0.48590, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 26: val_loss improved from 0.48590 to 0.43858, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.43858\n",
            "\n",
            "Epoch 34: val_loss improved from 0.43858 to 0.40795, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.40795\n",
            "\n",
            "Epoch 43: val_loss improved from 0.40795 to 0.38784, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.38784\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.38784\n",
            "\n",
            "Epoch 46: val_loss improved from 0.38784 to 0.36629, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.36629\n",
            "\n",
            "Epoch 48: val_loss improved from 0.36629 to 0.35426, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.35426\n",
            "\n",
            "Epoch 64: val_loss improved from 0.35426 to 0.34959, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.34959\n",
            "\n",
            "Epoch 66: val_loss improved from 0.34959 to 0.34147, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.34147\n",
            "\n",
            "Epoch 73: val_loss improved from 0.34147 to 0.31780, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.31780\n",
            "\n",
            "Epoch 93: val_loss improved from 0.31780 to 0.28991, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.28991\n",
            "\n",
            "Epoch 117: val_loss improved from 0.28991 to 0.28285, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 118: val_loss improved from 0.28285 to 0.26311, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 142: val_loss did not improve from 0.26311\n",
            "\n",
            "Epoch 143: val_loss improved from 0.26311 to 0.25553, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.25553\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.25553\n",
            "\n",
            "Epoch 146: val_loss improved from 0.25553 to 0.23426, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 151: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 152: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 153: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 154: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 155: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 156: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 157: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 158: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 159: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 160: val_loss did not improve from 0.23426\n",
            "\n",
            "Epoch 161: val_loss improved from 0.23426 to 0.22519, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 162: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 163: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 164: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 165: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 166: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 167: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 168: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 169: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 170: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 171: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 172: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 173: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 174: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 175: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 176: val_loss did not improve from 0.22519\n",
            "\n",
            "Epoch 177: val_loss improved from 0.22519 to 0.21136, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 178: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 179: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 180: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 181: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 182: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 183: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 184: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 185: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 186: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 187: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 188: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 189: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 190: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 191: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 192: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 193: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 194: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 195: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 196: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 197: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 198: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 199: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 200: val_loss did not improve from 0.21136\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.48686, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.48686 to 2.22101, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 2.22101 to 1.56091, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.56091 to 1.51337, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.51337 to 1.23671, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.23671 to 1.06236, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.06236\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.06236\n",
            "\n",
            "Epoch 9: val_loss improved from 1.06236 to 0.91106, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.91106 to 0.82308, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.82308 to 0.78682, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.78682\n",
            "\n",
            "Epoch 13: val_loss improved from 0.78682 to 0.69506, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.69506 to 0.63334, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.63334\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.63334\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.63334\n",
            "\n",
            "Epoch 18: val_loss improved from 0.63334 to 0.58272, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 19: val_loss improved from 0.58272 to 0.55169, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.55169\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.55169\n",
            "\n",
            "Epoch 22: val_loss improved from 0.55169 to 0.52169, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.52169\n",
            "\n",
            "Epoch 24: val_loss improved from 0.52169 to 0.49077, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.49077\n",
            "\n",
            "Epoch 32: val_loss improved from 0.49077 to 0.46979, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 33: val_loss improved from 0.46979 to 0.46579, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.46579\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.46579\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.46579\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.46579\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.46579\n",
            "\n",
            "Epoch 39: val_loss improved from 0.46579 to 0.41326, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.41326\n",
            "\n",
            "Epoch 50: val_loss improved from 0.41326 to 0.38621, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.38621\n",
            "\n",
            "Epoch 52: val_loss improved from 0.38621 to 0.37594, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.37594\n",
            "\n",
            "Epoch 74: val_loss improved from 0.37594 to 0.34621, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.34621\n",
            "\n",
            "Epoch 91: val_loss improved from 0.34621 to 0.32677, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.32677\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.32677\n",
            "Epoch 116: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.44240, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.44240 to 2.23887, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 2.23887 to 1.91362, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.91362 to 1.34881, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.34881\n",
            "\n",
            "Epoch 6: val_loss improved from 1.34881 to 1.06681, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.06681\n",
            "\n",
            "Epoch 8: val_loss improved from 1.06681 to 1.04632, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss improved from 1.04632 to 0.92867, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 0.92867 to 0.80640, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.80640\n",
            "\n",
            "Epoch 12: val_loss improved from 0.80640 to 0.73471, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.73471\n",
            "\n",
            "Epoch 14: val_loss improved from 0.73471 to 0.70702, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.70702 to 0.59437, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.59437\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.59437\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.59437\n",
            "\n",
            "Epoch 19: val_loss improved from 0.59437 to 0.59147, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.59147\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.59147\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.59147\n",
            "\n",
            "Epoch 23: val_loss improved from 0.59147 to 0.55125, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 24: val_loss improved from 0.55125 to 0.48423, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.48423\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.48423\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.48423\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.48423\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.48423\n",
            "\n",
            "Epoch 30: val_loss improved from 0.48423 to 0.47612, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.47612\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.47612\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.47612\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.47612\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.47612\n",
            "\n",
            "Epoch 36: val_loss improved from 0.47612 to 0.46260, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.46260\n",
            "\n",
            "Epoch 38: val_loss improved from 0.46260 to 0.42962, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.42962\n",
            "\n",
            "Epoch 50: val_loss improved from 0.42962 to 0.40890, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.40890\n",
            "\n",
            "Epoch 61: val_loss improved from 0.40890 to 0.40013, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.40013\n",
            "\n",
            "Epoch 71: val_loss improved from 0.40013 to 0.34920, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.34920\n",
            "\n",
            "Epoch 87: val_loss improved from 0.34920 to 0.32972, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.32972\n",
            "\n",
            "Epoch 108: val_loss improved from 0.32972 to 0.32052, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.32052\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.32052\n",
            "Epoch 133: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.29036, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.29036 to 2.09574, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 2.09574 to 1.72405, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.72405 to 1.41277, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.41277 to 1.37495, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.37495 to 1.18416, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.18416 to 1.05368, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.05368\n",
            "\n",
            "Epoch 9: val_loss improved from 1.05368 to 1.00044, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 10: val_loss improved from 1.00044 to 0.78188, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.78188\n",
            "\n",
            "Epoch 12: val_loss improved from 0.78188 to 0.68707, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.68707\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.68707\n",
            "\n",
            "Epoch 15: val_loss improved from 0.68707 to 0.66492, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.66492 to 0.63947, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.63947\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.63947\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.63947\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.63947\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.63947\n",
            "\n",
            "Epoch 22: val_loss improved from 0.63947 to 0.53759, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.53759\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.53759\n",
            "\n",
            "Epoch 25: val_loss improved from 0.53759 to 0.50034, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.50034\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.50034\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.50034\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.50034\n",
            "\n",
            "Epoch 30: val_loss improved from 0.50034 to 0.48369, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.48369\n",
            "\n",
            "Epoch 32: val_loss improved from 0.48369 to 0.42810, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.42810\n",
            "\n",
            "Epoch 54: val_loss improved from 0.42810 to 0.41433, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.41433\n",
            "\n",
            "Epoch 61: val_loss improved from 0.41433 to 0.39454, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 62: val_loss improved from 0.39454 to 0.34059, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.34059\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.34059\n",
            "Epoch 87: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.12789, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.12789\n",
            "\n",
            "Epoch 3: val_loss improved from 2.12789 to 1.78722, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.78722 to 1.47124, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss improved from 1.47124 to 1.32913, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.32913 to 1.16677, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.16677 to 1.14208, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.14208 to 1.10663, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 1.10663\n",
            "\n",
            "Epoch 10: val_loss improved from 1.10663 to 0.82196, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.82196\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.82196\n",
            "\n",
            "Epoch 13: val_loss improved from 0.82196 to 0.71488, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 14: val_loss improved from 0.71488 to 0.69866, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.69866 to 0.65098, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss improved from 0.65098 to 0.64965, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.64965\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.64965\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.64965\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.64965\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.64965\n",
            "\n",
            "Epoch 22: val_loss improved from 0.64965 to 0.60804, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.60804\n",
            "\n",
            "Epoch 24: val_loss improved from 0.60804 to 0.60782, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.60782 to 0.49887, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.49887\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.49887\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.49887\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.49887\n",
            "\n",
            "Epoch 30: val_loss improved from 0.49887 to 0.45619, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.45619\n",
            "\n",
            "Epoch 47: val_loss improved from 0.45619 to 0.42987, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.42987\n",
            "\n",
            "Epoch 60: val_loss improved from 0.42987 to 0.41532, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.41532\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.41532\n",
            "\n",
            "Epoch 63: val_loss improved from 0.41532 to 0.38194, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.38194\n",
            "\n",
            "Epoch 71: val_loss improved from 0.38194 to 0.37422, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.37422\n",
            "\n",
            "Epoch 80: val_loss improved from 0.37422 to 0.36758, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.36758\n",
            "\n",
            "Epoch 82: val_loss improved from 0.36758 to 0.32205, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.32205\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.32205\n",
            "Epoch 107: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.43312, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.43312 to 1.90070, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 1.90070 to 1.59537, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.59537\n",
            "\n",
            "Epoch 5: val_loss improved from 1.59537 to 1.33605, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 1.33605 to 1.16069, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.16069 to 1.13794, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.13794 to 0.97736, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.97736\n",
            "\n",
            "Epoch 10: val_loss improved from 0.97736 to 0.88368, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.88368\n",
            "\n",
            "Epoch 12: val_loss improved from 0.88368 to 0.80190, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.80190\n",
            "\n",
            "Epoch 14: val_loss improved from 0.80190 to 0.73944, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.73944 to 0.58770, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.58770\n",
            "\n",
            "Epoch 22: val_loss improved from 0.58770 to 0.53632, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.53632\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.53632\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.53632\n",
            "\n",
            "Epoch 26: val_loss improved from 0.53632 to 0.45500, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.45500\n",
            "\n",
            "Epoch 48: val_loss improved from 0.45500 to 0.43111, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.43111\n",
            "\n",
            "Epoch 55: val_loss improved from 0.43111 to 0.40310, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.40310\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.40310\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.40310\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.40310\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.40310\n",
            "\n",
            "Epoch 61: val_loss improved from 0.40310 to 0.40167, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.40167\n",
            "\n",
            "Epoch 63: val_loss improved from 0.40167 to 0.39822, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 64: val_loss improved from 0.39822 to 0.39040, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.39040\n",
            "\n",
            "Epoch 71: val_loss improved from 0.39040 to 0.37745, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.37745\n",
            "\n",
            "Epoch 79: val_loss improved from 0.37745 to 0.36810, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.36810\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.36810\n",
            "\n",
            "Epoch 82: val_loss improved from 0.36810 to 0.35776, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.35776\n",
            "\n",
            "Epoch 94: val_loss improved from 0.35776 to 0.33837, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.33837\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.33837\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.33837\n",
            "\n",
            "Epoch 98: val_loss improved from 0.33837 to 0.32644, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.32644\n",
            "\n",
            "Epoch 109: val_loss improved from 0.32644 to 0.32213, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.32213\n",
            "\n",
            "Epoch 111: val_loss improved from 0.32213 to 0.31987, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.31987\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.31987\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.31987\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.31987\n",
            "\n",
            "Epoch 116: val_loss improved from 0.31987 to 0.25050, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.25050\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.25050\n",
            "Epoch 141: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.20783, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 2.20783 to 2.17235, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 2.17235 to 1.48875, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss improved from 1.48875 to 1.33132, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.33132\n",
            "\n",
            "Epoch 6: val_loss improved from 1.33132 to 1.17704, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 1.17704 to 1.15599, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss improved from 1.15599 to 0.91584, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.91584\n",
            "\n",
            "Epoch 10: val_loss improved from 0.91584 to 0.84423, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 11: val_loss improved from 0.84423 to 0.81711, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.81711\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.81711\n",
            "\n",
            "Epoch 14: val_loss improved from 0.81711 to 0.65049, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.65049 to 0.63566, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.63566\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.63566\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.63566\n",
            "\n",
            "Epoch 19: val_loss improved from 0.63566 to 0.62973, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 20: val_loss improved from 0.62973 to 0.62637, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.62637\n",
            "\n",
            "Epoch 22: val_loss improved from 0.62637 to 0.58206, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.58206\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.58206\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.58206\n",
            "\n",
            "Epoch 26: val_loss improved from 0.58206 to 0.49750, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.49750\n",
            "\n",
            "Epoch 37: val_loss improved from 0.49750 to 0.48837, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.48837\n",
            "\n",
            "Epoch 45: val_loss improved from 0.48837 to 0.48773, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.48773\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.48773\n",
            "\n",
            "Epoch 48: val_loss improved from 0.48773 to 0.47671, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.47671\n",
            "\n",
            "Epoch 56: val_loss improved from 0.47671 to 0.43459, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.43459\n",
            "\n",
            "Epoch 68: val_loss improved from 0.43459 to 0.42098, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.42098\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.42098\n",
            "\n",
            "Epoch 71: val_loss improved from 0.42098 to 0.40088, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.40088\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.40088\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.40088\n",
            "\n",
            "Epoch 75: val_loss improved from 0.40088 to 0.39847, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.39847\n",
            "\n",
            "Epoch 86: val_loss improved from 0.39847 to 0.38745, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.38745\n",
            "\n",
            "Epoch 107: val_loss improved from 0.38745 to 0.33649, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.33649\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.33649\n",
            "Epoch 132: early stopping\n",
            "mean correlation 0.623074655770636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing the LSTM structure for one person"
      ],
      "metadata": {
        "id": "YuDJaqHQoNR3"
      },
      "id": "YuDJaqHQoNR3"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "\n",
        "data = np.load(r'/content/features/sub-01_feat.npy')\n",
        "spectrogram = np.load(r'/content/features/sub-01_spec.npy')\n",
        "\n",
        "#Inital parameters\n",
        "nfolds = 10\n",
        "kf = KFold(nfolds,shuffle=False)\n",
        "pca = PCA()\n",
        "numComps = 300\n",
        "val_split = 0.2\n",
        "\n",
        "#Audio Reconstruction parameters\n",
        "winLength = 0.05\n",
        "frameshift = 0.01\n",
        "audiosr = 16000\n",
        "\n",
        "#Initialize an empty spectrogram to save the reconstruction to\n",
        "rec_spec = np.zeros(spectrogram.shape)\n",
        "#Save the correlation coefficients for each fold\n",
        "rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "for k,(train, test) in enumerate(kf.split(data)):         \n",
        "    #Train, validation and test data\n",
        "    X_train_temp = data[train,:]\n",
        "    y_train_temp = spectrogram[train,:]\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=val_split, random_state=0, shuffle=False)\n",
        "    X_test = data[test,:]\n",
        "    y_test = spectrogram[test,:] # this one might not be needed\n",
        "    \n",
        "    #Normalization\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train[:] = scaler.transform(X_train)\n",
        "    X_val[:] = scaler.transform(X_val)\n",
        "    X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "    #Fit PCA to training data\n",
        "    pca.fit(X_train)\n",
        "    #Tranform data \n",
        "    X_train = np.dot(X_train, pca.components_[:numComps,:].T)\n",
        "    X_val = np.dot(X_val, pca.components_[:numComps,:].T)\n",
        "    X_test = np.dot(X_test, pca.components_[:numComps,:].T)\n",
        "\n",
        "    # LSTM model\n",
        "    early_stopping=EarlyStopping(patience=25, verbose=1, min_delta=1e-5)\n",
        "    checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "    model = create_LSTM_model(numComps, spectrogram.shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    model.fit(X_train, y_train, batch_size=64, \n",
        "              epochs=100, verbose=0, validation_data=(X_val, y_val), shuffle=True,\n",
        "              callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "    #predict with the Autoencoder\n",
        "    model.load_weights('weights1.hdf5')\n",
        "    rec_spec[test, :] = model.predict(X_test, verbose=0)\n",
        "\n",
        "    #Evaluate reconstruction of this fold\n",
        "    for specBin in range(spectrogram.shape[1]):\n",
        "         r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "         rs[k,specBin] = r\n",
        "\n",
        "\n",
        "#Show evaluation result\n",
        "print('mean correlation', np.mean(rs))\n",
        "\n",
        "#Make and save the synthesized audio\n",
        "reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "wavfile.write(os.path.join('/content/synth_audio/sub-01_predicted.wav'),int(audiosr),reconstructedWav)"
      ],
      "metadata": {
        "id": "ifhJLOucoM3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9694a797-55a9-423e-cd9e-54388613b7ca"
      },
      "id": "ifhJLOucoM3d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.36893, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.36893\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.36893\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.37300, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.37300\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.37300\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.33568, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.33568\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.33568\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.40489, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.40489\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.40489\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.47018, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.47018\n",
            "\n",
            "Epoch 3: val_loss improved from 2.47018 to 2.41638, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 27: val_loss did not improve from 2.41638\n",
            "\n",
            "Epoch 28: val_loss did not improve from 2.41638\n",
            "Epoch 28: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.37603, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.37603\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.37603\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.41114, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.41114\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.41114\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.42622, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.42622\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.42622\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.60844, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.60844\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.60844\n",
            "Epoch 26: early stopping\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.11427, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 3: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 4: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 5: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.11427\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.11427\n",
            "Epoch 26: early stopping\n",
            "mean correlation 0.5629516076353095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizing the CNN structure for one person"
      ],
      "metadata": {
        "id": "JASkuUZGO6Di"
      },
      "id": "JASkuUZGO6Di"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.io.wavfile as wavfile\n",
        "\n",
        "\n",
        "data = np.load(r'/content/features/sub-01_feat.npy')\n",
        "spectrogram = np.load(r'/content/features/sub-01_spec.npy')\n",
        "\n",
        "#Inital parameters\n",
        "nfolds = 10\n",
        "kf = KFold(nfolds,shuffle=False)\n",
        "pca = PCA()\n",
        "numComps = 200\n",
        "val_split = 0.2\n",
        "window = 20\n",
        "\n",
        "#Audio Reconstruction parameters\n",
        "winLength = 0.05\n",
        "frameshift = 0.01\n",
        "audiosr = 16000\n",
        "\n",
        "#Initialize an empty spectrogram to save the reconstruction to\n",
        "rec_spec = np.zeros(spectrogram.shape)\n",
        "#Save the correlation coefficients for each fold\n",
        "rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "for k,(train, test) in enumerate(kf.split(data)):         \n",
        "    #Train, validation and test data\n",
        "    X_train_temp = data[train,:]\n",
        "    y_train_temp = spectrogram[train,:]\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=val_split, random_state=0, shuffle=False)\n",
        "    X_test = data[test,:]\n",
        "    y_test = spectrogram[test,:] # this one might not be needed\n",
        "    \n",
        "    #Normalization\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train[:] = scaler.transform(X_train)\n",
        "    X_val[:] = scaler.transform(X_val)\n",
        "    X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "    #Fit PCA to training data\n",
        "    pca.fit(X_train)\n",
        "    #Tranform data \n",
        "    X_train = np.dot(X_train, pca.components_[:numComps,:].T)\n",
        "    X_val = np.dot(X_val, pca.components_[:numComps,:].T)\n",
        "    X_test = np.dot(X_test, pca.components_[:numComps,:].T)\n",
        "\n",
        "    #reshaping the data\n",
        "    X_train = cnnize(X_train, window)\n",
        "    X_val = cnnize(X_val, window)\n",
        "    X_test = cnnize(X_test, window)\n",
        "\n",
        "    #CNN model\n",
        "    early_stopping=EarlyStopping(patience=25, verbose=1, min_delta=1e-5)\n",
        "    checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "    model = create_cnn_model(int((numComps-window)/2)+1, window, spectrogram.shape[1])\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    model.fit(X_train, y_train, batch_size=64, \n",
        "              epochs=100, verbose=0, validation_data=(X_val, y_val), shuffle=True,\n",
        "              callbacks=[checkpointer, early_stopping])\n",
        "            \n",
        "    #predict with the Autoencoder\n",
        "    model.load_weights('weights1.hdf5')\n",
        "    rec_spec[test, :] = model.predict(X_test, verbose=0)\n",
        "\n",
        "    #Evaluate reconstruction of this fold\n",
        "    for specBin in range(spectrogram.shape[1]):\n",
        "         r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "         rs[k,specBin] = r\n",
        "\n",
        "\n",
        "#Show evaluation result\n",
        "print('mean correlation', np.mean(rs))\n",
        "\n",
        "#Make and save the synthesized audio\n",
        "reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "wavfile.write(os.path.join('/content/synth_audio/sub-01_predicted.wav'),int(audiosr),reconstructedWav)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JmcptaXXO1Sj",
        "outputId": "4fddf724-e61b-4041-e957-a3e67bd975e9"
      },
      "id": "JmcptaXXO1Sj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 3.65074, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 2: val_loss improved from 3.65074 to 3.44781, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 3: val_loss improved from 3.44781 to 3.12265, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 4: val_loss did not improve from 3.12265\n",
            "\n",
            "Epoch 5: val_loss improved from 3.12265 to 3.09337, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 6: val_loss improved from 3.09337 to 2.97692, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 7: val_loss improved from 2.97692 to 2.92251, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.92251\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.92251\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.92251\n",
            "\n",
            "Epoch 11: val_loss improved from 2.92251 to 2.87664, saving model to weights1.hdf5\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 27: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 28: val_loss did not improve from 2.87664\n",
            "\n",
            "Epoch 29: val_loss did not improve from 2.87664\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-dfc07efd962f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     model.fit(X_train, y_train, batch_size=64, \n\u001b[1;32m     62\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m               callbacks=[checkpointer, early_stopping])\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m#predict with the Autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.) Trying out the best configuration for every subject"
      ],
      "metadata": {
        "id": "8puXSrNvPks0"
      },
      "id": "8puXSrNvPks0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c0796a",
      "metadata": {
        "id": "31c0796a"
      },
      "outputs": [],
      "source": [
        "##### MODELING ########\n",
        "\n",
        "# So far, the best performance came from the normal DNN model\n",
        "\n",
        "model = True\n",
        "\n",
        "scores= []\n",
        "\n",
        "if model == True:\n",
        "    feat_path = r'/content/features'\n",
        "    result_path = r'/content/synth_audio'\n",
        "    pts = ['sub-%02d'%i for i in range(1,11)]\n",
        "\n",
        "    winLength = 0.05\n",
        "    frameshift = 0.01\n",
        "    audiosr = 16000\n",
        "\n",
        "    nfolds = 15\n",
        "    kf = KFold(nfolds,shuffle=False)\n",
        "    pca = PCA()\n",
        "    numComps = 400\n",
        "    \n",
        "    #Initialize empty matrices for correlation results, randomized controls and amount of explained variance\n",
        "    allRes = np.zeros((len(pts),nfolds,23))\n",
        "\n",
        "    for pNr, pt in enumerate(pts):\n",
        "        \n",
        "        \n",
        "        #Load the data\n",
        "        #Dimensions of these data vary depending on the subject\n",
        "        spectrogram = np.load(os.path.join(feat_path,f'{pt}_spec.npy'))  \n",
        "        data = np.load(os.path.join(feat_path,f'{pt}_feat.npy'))\n",
        "\n",
        "        \n",
        "        #Initialize an empty spectrogram to save the reconstruction to\n",
        "        rec_spec = np.zeros(spectrogram.shape)\n",
        "        #Save the correlation coefficients for each fold\n",
        "        rs = np.zeros((nfolds,spectrogram.shape[1]))\n",
        "        for k,(train, test) in enumerate(kf.split(data)):\n",
        "          \n",
        "            #Train, validation and test data\n",
        "            X_train_temp = data[train,:]\n",
        "            y_train_temp = spectrogram[train,:]\n",
        "            X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=val_split, random_state=0)\n",
        "            X_test = data[test,:]\n",
        "            y_test = spectrogram[test,:] # this one might not be needed\n",
        "            \n",
        "            #Normalization\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(X_train)\n",
        "            X_train[:] = scaler.transform(X_train)\n",
        "            X_val[:] = scaler.transform(X_val)\n",
        "            X_test[:] = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "            #Fit PCA to training data\n",
        "            pca.fit(X_train)\n",
        "            #Tranform data \n",
        "            X_train = np.dot(X_train, pca.components_[:numComps,:].T)\n",
        "            X_val = np.dot(X_val, pca.components_[:numComps,:].T)\n",
        "            X_test = np.dot(X_test, pca.components_[:numComps,:].T)\n",
        "\n",
        "            # normal DNN model\n",
        "            early_stopping=EarlyStopping(patience=25, verbose=0, min_delta=1e-5)\n",
        "            checkpointer=ModelCheckpoint(filepath='weights1.hdf5', save_best_only=True, verbose=0)\n",
        "\n",
        "            model = create_dnn_model(numComps, spectrogram.shape[1])\n",
        "            model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "            model.fit(X_train, y_train, batch_size=64, \n",
        "                      epochs=100, verbose=0, validation_data=(X_val, y_val), shuffle=True,\n",
        "                      callbacks=[checkpointer, early_stopping])\n",
        "                    \n",
        "            #predict with the Autoencoder\n",
        "            model.load_weights('weights1.hdf5')\n",
        "            rec_spec[test, :] = model.predict(X_test, verbose=0)\n",
        "\n",
        "            #Evaluate reconstruction of this fold\n",
        "            for specBin in range(spectrogram.shape[1]):\n",
        "                if np.any(np.isnan(rec_spec)):\n",
        "                    print('%s has %d broken samples in reconstruction' % (pt, np.sum(np.isnan(rec_spec))))\n",
        "                r, p = pearsonr(spectrogram[test, specBin], rec_spec[test, specBin])\n",
        "                rs[k,specBin] = r\n",
        "\n",
        "        #Show evaluation result\n",
        "        print('%s has mean correlation of %f' % (pt, np.mean(rs)))\n",
        "        allRes[pNr,:,:]=rs\n",
        "        scores.append(np.mean(rs))\n",
        "\n",
        "\n",
        "        #Make and save the synthesized audio\n",
        "        reconstructedWav = createAudio(rec_spec,audiosr=audiosr,winLength=winLength,frameshift=frameshift)\n",
        "        wavfile.write(os.path.join('/content/synth_audio/','sub-01_predicted.wav'),int(audiosr),reconstructedWav)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6e6b40",
      "metadata": {
        "id": "0a6e6b40",
        "outputId": "4e3b10f6-a443-47ac-e2b6-c6eba396472d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5629875535958715,\n",
              " 0.615317710223286,\n",
              " 0.8574981748428402,\n",
              " 0.816490556136459,\n",
              " 0.5712122543230624,\n",
              " 0.8819938942481294,\n",
              " 0.7771201475020989,\n",
              " 0.6878816278290169,\n",
              " 0.7386449014724298,\n",
              " 0.7146618900721041]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6FcMJWfW_99"
      },
      "id": "R6FcMJWfW_99",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}